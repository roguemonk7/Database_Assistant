{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "183a7b4d-5d56-411a-ab6d-60a76aa2de86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\varun\\anaconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\varun\\anaconda3\\lib\\site-packages (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbb7c64c-a71d-4268-93e6-ec19c37c219e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlalchemy in c:\\users\\varun\\anaconda3\\lib\\site-packages (2.0.34)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from sqlalchemy) (4.13.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from sqlalchemy) (3.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "514e8592-78df-44ce-8d30-d418216e3c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('penguins.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b789b1d6-6b7a-4a93-a0fb-33ab5d875383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "3  Adelie  Torgersen             NaN            NaN                NaN   \n",
       "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
       "\n",
       "   body_mass_g     sex  \n",
       "0       3750.0    MALE  \n",
       "1       3800.0  FEMALE  \n",
       "2       3250.0  FEMALE  \n",
       "3          NaN     NaN  \n",
       "4       3450.0  FEMALE  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb87e4f3-6e7a-4615-b985-05ec2b0fcdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "281d9788-3040-4ce4-b1d3-803ea2b1576b",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_db = create_engine('sqlite:///:memory:',echo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c84d186d-48dc-453d-ac70-b4bc3abb189d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-20 21:26:30,319 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-04-20 21:26:30,322 INFO sqlalchemy.engine.Engine PRAGMA main.table_info(\"Penguins\")\n",
      "2025-04-20 21:26:30,325 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-04-20 21:26:30,326 INFO sqlalchemy.engine.Engine PRAGMA temp.table_info(\"Penguins\")\n",
      "2025-04-20 21:26:30,327 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-04-20 21:26:30,329 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE \"Penguins\" (\n",
      "\t\"index\" BIGINT, \n",
      "\tspecies TEXT, \n",
      "\tisland TEXT, \n",
      "\tbill_length_mm FLOAT, \n",
      "\tbill_depth_mm FLOAT, \n",
      "\tflipper_length_mm FLOAT, \n",
      "\tbody_mass_g FLOAT, \n",
      "\tsex TEXT\n",
      ")\n",
      "\n",
      "\n",
      "2025-04-20 21:26:30,330 INFO sqlalchemy.engine.Engine [no key 0.00090s] ()\n",
      "2025-04-20 21:26:30,332 INFO sqlalchemy.engine.Engine CREATE INDEX \"ix_Penguins_index\" ON \"Penguins\" (\"index\")\n",
      "2025-04-20 21:26:30,333 INFO sqlalchemy.engine.Engine [no key 0.00081s] ()\n",
      "2025-04-20 21:26:30,341 INFO sqlalchemy.engine.Engine INSERT INTO \"Penguins\" (\"index\", species, island, bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g, sex) VALUES (?, ?, ?, ?, ?, ?, ?, ?)\n",
      "2025-04-20 21:26:30,342 INFO sqlalchemy.engine.Engine [generated in 0.00400s] [(0, 'Adelie', 'Torgersen', 39.1, 18.7, 181.0, 3750.0, 'MALE'), (1, 'Adelie', 'Torgersen', 39.5, 17.4, 186.0, 3800.0, 'FEMALE'), (2, 'Adelie', 'Torgersen', 40.3, 18.0, 195.0, 3250.0, 'FEMALE'), (3, 'Adelie', 'Torgersen', None, None, None, None, None), (4, 'Adelie', 'Torgersen', 36.7, 19.3, 193.0, 3450.0, 'FEMALE'), (5, 'Adelie', 'Torgersen', 39.3, 20.6, 190.0, 3650.0, 'MALE'), (6, 'Adelie', 'Torgersen', 38.9, 17.8, 181.0, 3625.0, 'FEMALE'), (7, 'Adelie', 'Torgersen', 39.2, 19.6, 195.0, 4675.0, 'MALE')  ... displaying 10 of 344 total bound parameter sets ...  (342, 'Gentoo', 'Biscoe', 45.2, 14.8, 212.0, 5200.0, 'FEMALE'), (343, 'Gentoo', 'Biscoe', 49.9, 16.1, 213.0, 5400.0, 'MALE')]\n",
      "2025-04-20 21:26:30,345 INFO sqlalchemy.engine.Engine SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite~_%' ESCAPE '~' ORDER BY name\n",
      "2025-04-20 21:26:30,346 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2025-04-20 21:26:30,347 INFO sqlalchemy.engine.Engine COMMIT\n"
     ]
    }
   ],
   "source": [
    "data= df.to_sql(name='Penguins',con=temp_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb822827-6f9b-4ad4-907e-a3d8eafac591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-20 21:26:38,435 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2025-04-20 21:26:38,436 INFO sqlalchemy.engine.Engine SELECT * from Penguins\n",
      "2025-04-20 21:26:38,437 INFO sqlalchemy.engine.Engine [generated in 0.00252s] ()\n",
      "2025-04-20 21:26:38,439 INFO sqlalchemy.engine.Engine ROLLBACK\n"
     ]
    }
   ],
   "source": [
    "with temp_db.connect() as conn:\n",
    "    result = conn.execute(text(\"SELECT * from Penguins\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9bfbfbd-610a-4ab3-b845-94a02ebf799f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'Adelie', 'Torgersen', 39.1, 18.7, 181.0, 3750.0, 'MALE'),\n",
       " (1, 'Adelie', 'Torgersen', 39.5, 17.4, 186.0, 3800.0, 'FEMALE'),\n",
       " (2, 'Adelie', 'Torgersen', 40.3, 18.0, 195.0, 3250.0, 'FEMALE'),\n",
       " (3, 'Adelie', 'Torgersen', None, None, None, None, None),\n",
       " (4, 'Adelie', 'Torgersen', 36.7, 19.3, 193.0, 3450.0, 'FEMALE'),\n",
       " (5, 'Adelie', 'Torgersen', 39.3, 20.6, 190.0, 3650.0, 'MALE'),\n",
       " (6, 'Adelie', 'Torgersen', 38.9, 17.8, 181.0, 3625.0, 'FEMALE'),\n",
       " (7, 'Adelie', 'Torgersen', 39.2, 19.6, 195.0, 4675.0, 'MALE'),\n",
       " (8, 'Adelie', 'Torgersen', 34.1, 18.1, 193.0, 3475.0, None),\n",
       " (9, 'Adelie', 'Torgersen', 42.0, 20.2, 190.0, 4250.0, None),\n",
       " (10, 'Adelie', 'Torgersen', 37.8, 17.1, 186.0, 3300.0, None),\n",
       " (11, 'Adelie', 'Torgersen', 37.8, 17.3, 180.0, 3700.0, None),\n",
       " (12, 'Adelie', 'Torgersen', 41.1, 17.6, 182.0, 3200.0, 'FEMALE'),\n",
       " (13, 'Adelie', 'Torgersen', 38.6, 21.2, 191.0, 3800.0, 'MALE'),\n",
       " (14, 'Adelie', 'Torgersen', 34.6, 21.1, 198.0, 4400.0, 'MALE'),\n",
       " (15, 'Adelie', 'Torgersen', 36.6, 17.8, 185.0, 3700.0, 'FEMALE'),\n",
       " (16, 'Adelie', 'Torgersen', 38.7, 19.0, 195.0, 3450.0, 'FEMALE'),\n",
       " (17, 'Adelie', 'Torgersen', 42.5, 20.7, 197.0, 4500.0, 'MALE'),\n",
       " (18, 'Adelie', 'Torgersen', 34.4, 18.4, 184.0, 3325.0, 'FEMALE'),\n",
       " (19, 'Adelie', 'Torgersen', 46.0, 21.5, 194.0, 4200.0, 'MALE'),\n",
       " (20, 'Adelie', 'Biscoe', 37.8, 18.3, 174.0, 3400.0, 'FEMALE'),\n",
       " (21, 'Adelie', 'Biscoe', 37.7, 18.7, 180.0, 3600.0, 'MALE'),\n",
       " (22, 'Adelie', 'Biscoe', 35.9, 19.2, 189.0, 3800.0, 'FEMALE'),\n",
       " (23, 'Adelie', 'Biscoe', 38.2, 18.1, 185.0, 3950.0, 'MALE'),\n",
       " (24, 'Adelie', 'Biscoe', 38.8, 17.2, 180.0, 3800.0, 'MALE'),\n",
       " (25, 'Adelie', 'Biscoe', 35.3, 18.9, 187.0, 3800.0, 'FEMALE'),\n",
       " (26, 'Adelie', 'Biscoe', 40.6, 18.6, 183.0, 3550.0, 'MALE'),\n",
       " (27, 'Adelie', 'Biscoe', 40.5, 17.9, 187.0, 3200.0, 'FEMALE'),\n",
       " (28, 'Adelie', 'Biscoe', 37.9, 18.6, 172.0, 3150.0, 'FEMALE'),\n",
       " (29, 'Adelie', 'Biscoe', 40.5, 18.9, 180.0, 3950.0, 'MALE'),\n",
       " (30, 'Adelie', 'Dream', 39.5, 16.7, 178.0, 3250.0, 'FEMALE'),\n",
       " (31, 'Adelie', 'Dream', 37.2, 18.1, 178.0, 3900.0, 'MALE'),\n",
       " (32, 'Adelie', 'Dream', 39.5, 17.8, 188.0, 3300.0, 'FEMALE'),\n",
       " (33, 'Adelie', 'Dream', 40.9, 18.9, 184.0, 3900.0, 'MALE'),\n",
       " (34, 'Adelie', 'Dream', 36.4, 17.0, 195.0, 3325.0, 'FEMALE'),\n",
       " (35, 'Adelie', 'Dream', 39.2, 21.1, 196.0, 4150.0, 'MALE'),\n",
       " (36, 'Adelie', 'Dream', 38.8, 20.0, 190.0, 3950.0, 'MALE'),\n",
       " (37, 'Adelie', 'Dream', 42.2, 18.5, 180.0, 3550.0, 'FEMALE'),\n",
       " (38, 'Adelie', 'Dream', 37.6, 19.3, 181.0, 3300.0, 'FEMALE'),\n",
       " (39, 'Adelie', 'Dream', 39.8, 19.1, 184.0, 4650.0, 'MALE'),\n",
       " (40, 'Adelie', 'Dream', 36.5, 18.0, 182.0, 3150.0, 'FEMALE'),\n",
       " (41, 'Adelie', 'Dream', 40.8, 18.4, 195.0, 3900.0, 'MALE'),\n",
       " (42, 'Adelie', 'Dream', 36.0, 18.5, 186.0, 3100.0, 'FEMALE'),\n",
       " (43, 'Adelie', 'Dream', 44.1, 19.7, 196.0, 4400.0, 'MALE'),\n",
       " (44, 'Adelie', 'Dream', 37.0, 16.9, 185.0, 3000.0, 'FEMALE'),\n",
       " (45, 'Adelie', 'Dream', 39.6, 18.8, 190.0, 4600.0, 'MALE'),\n",
       " (46, 'Adelie', 'Dream', 41.1, 19.0, 182.0, 3425.0, 'MALE'),\n",
       " (47, 'Adelie', 'Dream', 37.5, 18.9, 179.0, 2975.0, None),\n",
       " (48, 'Adelie', 'Dream', 36.0, 17.9, 190.0, 3450.0, 'FEMALE'),\n",
       " (49, 'Adelie', 'Dream', 42.3, 21.2, 191.0, 4150.0, 'MALE'),\n",
       " (50, 'Adelie', 'Biscoe', 39.6, 17.7, 186.0, 3500.0, 'FEMALE'),\n",
       " (51, 'Adelie', 'Biscoe', 40.1, 18.9, 188.0, 4300.0, 'MALE'),\n",
       " (52, 'Adelie', 'Biscoe', 35.0, 17.9, 190.0, 3450.0, 'FEMALE'),\n",
       " (53, 'Adelie', 'Biscoe', 42.0, 19.5, 200.0, 4050.0, 'MALE'),\n",
       " (54, 'Adelie', 'Biscoe', 34.5, 18.1, 187.0, 2900.0, 'FEMALE'),\n",
       " (55, 'Adelie', 'Biscoe', 41.4, 18.6, 191.0, 3700.0, 'MALE'),\n",
       " (56, 'Adelie', 'Biscoe', 39.0, 17.5, 186.0, 3550.0, 'FEMALE'),\n",
       " (57, 'Adelie', 'Biscoe', 40.6, 18.8, 193.0, 3800.0, 'MALE'),\n",
       " (58, 'Adelie', 'Biscoe', 36.5, 16.6, 181.0, 2850.0, 'FEMALE'),\n",
       " (59, 'Adelie', 'Biscoe', 37.6, 19.1, 194.0, 3750.0, 'MALE'),\n",
       " (60, 'Adelie', 'Biscoe', 35.7, 16.9, 185.0, 3150.0, 'FEMALE'),\n",
       " (61, 'Adelie', 'Biscoe', 41.3, 21.1, 195.0, 4400.0, 'MALE'),\n",
       " (62, 'Adelie', 'Biscoe', 37.6, 17.0, 185.0, 3600.0, 'FEMALE'),\n",
       " (63, 'Adelie', 'Biscoe', 41.1, 18.2, 192.0, 4050.0, 'MALE'),\n",
       " (64, 'Adelie', 'Biscoe', 36.4, 17.1, 184.0, 2850.0, 'FEMALE'),\n",
       " (65, 'Adelie', 'Biscoe', 41.6, 18.0, 192.0, 3950.0, 'MALE'),\n",
       " (66, 'Adelie', 'Biscoe', 35.5, 16.2, 195.0, 3350.0, 'FEMALE'),\n",
       " (67, 'Adelie', 'Biscoe', 41.1, 19.1, 188.0, 4100.0, 'MALE'),\n",
       " (68, 'Adelie', 'Torgersen', 35.9, 16.6, 190.0, 3050.0, 'FEMALE'),\n",
       " (69, 'Adelie', 'Torgersen', 41.8, 19.4, 198.0, 4450.0, 'MALE'),\n",
       " (70, 'Adelie', 'Torgersen', 33.5, 19.0, 190.0, 3600.0, 'FEMALE'),\n",
       " (71, 'Adelie', 'Torgersen', 39.7, 18.4, 190.0, 3900.0, 'MALE'),\n",
       " (72, 'Adelie', 'Torgersen', 39.6, 17.2, 196.0, 3550.0, 'FEMALE'),\n",
       " (73, 'Adelie', 'Torgersen', 45.8, 18.9, 197.0, 4150.0, 'MALE'),\n",
       " (74, 'Adelie', 'Torgersen', 35.5, 17.5, 190.0, 3700.0, 'FEMALE'),\n",
       " (75, 'Adelie', 'Torgersen', 42.8, 18.5, 195.0, 4250.0, 'MALE'),\n",
       " (76, 'Adelie', 'Torgersen', 40.9, 16.8, 191.0, 3700.0, 'FEMALE'),\n",
       " (77, 'Adelie', 'Torgersen', 37.2, 19.4, 184.0, 3900.0, 'MALE'),\n",
       " (78, 'Adelie', 'Torgersen', 36.2, 16.1, 187.0, 3550.0, 'FEMALE'),\n",
       " (79, 'Adelie', 'Torgersen', 42.1, 19.1, 195.0, 4000.0, 'MALE'),\n",
       " (80, 'Adelie', 'Torgersen', 34.6, 17.2, 189.0, 3200.0, 'FEMALE'),\n",
       " (81, 'Adelie', 'Torgersen', 42.9, 17.6, 196.0, 4700.0, 'MALE'),\n",
       " (82, 'Adelie', 'Torgersen', 36.7, 18.8, 187.0, 3800.0, 'FEMALE'),\n",
       " (83, 'Adelie', 'Torgersen', 35.1, 19.4, 193.0, 4200.0, 'MALE'),\n",
       " (84, 'Adelie', 'Dream', 37.3, 17.8, 191.0, 3350.0, 'FEMALE'),\n",
       " (85, 'Adelie', 'Dream', 41.3, 20.3, 194.0, 3550.0, 'MALE'),\n",
       " (86, 'Adelie', 'Dream', 36.3, 19.5, 190.0, 3800.0, 'MALE'),\n",
       " (87, 'Adelie', 'Dream', 36.9, 18.6, 189.0, 3500.0, 'FEMALE'),\n",
       " (88, 'Adelie', 'Dream', 38.3, 19.2, 189.0, 3950.0, 'MALE'),\n",
       " (89, 'Adelie', 'Dream', 38.9, 18.8, 190.0, 3600.0, 'FEMALE'),\n",
       " (90, 'Adelie', 'Dream', 35.7, 18.0, 202.0, 3550.0, 'FEMALE'),\n",
       " (91, 'Adelie', 'Dream', 41.1, 18.1, 205.0, 4300.0, 'MALE'),\n",
       " (92, 'Adelie', 'Dream', 34.0, 17.1, 185.0, 3400.0, 'FEMALE'),\n",
       " (93, 'Adelie', 'Dream', 39.6, 18.1, 186.0, 4450.0, 'MALE'),\n",
       " (94, 'Adelie', 'Dream', 36.2, 17.3, 187.0, 3300.0, 'FEMALE'),\n",
       " (95, 'Adelie', 'Dream', 40.8, 18.9, 208.0, 4300.0, 'MALE'),\n",
       " (96, 'Adelie', 'Dream', 38.1, 18.6, 190.0, 3700.0, 'FEMALE'),\n",
       " (97, 'Adelie', 'Dream', 40.3, 18.5, 196.0, 4350.0, 'MALE'),\n",
       " (98, 'Adelie', 'Dream', 33.1, 16.1, 178.0, 2900.0, 'FEMALE'),\n",
       " (99, 'Adelie', 'Dream', 43.2, 18.5, 192.0, 4100.0, 'MALE'),\n",
       " (100, 'Adelie', 'Biscoe', 35.0, 17.9, 192.0, 3725.0, 'FEMALE'),\n",
       " (101, 'Adelie', 'Biscoe', 41.0, 20.0, 203.0, 4725.0, 'MALE'),\n",
       " (102, 'Adelie', 'Biscoe', 37.7, 16.0, 183.0, 3075.0, 'FEMALE'),\n",
       " (103, 'Adelie', 'Biscoe', 37.8, 20.0, 190.0, 4250.0, 'MALE'),\n",
       " (104, 'Adelie', 'Biscoe', 37.9, 18.6, 193.0, 2925.0, 'FEMALE'),\n",
       " (105, 'Adelie', 'Biscoe', 39.7, 18.9, 184.0, 3550.0, 'MALE'),\n",
       " (106, 'Adelie', 'Biscoe', 38.6, 17.2, 199.0, 3750.0, 'FEMALE'),\n",
       " (107, 'Adelie', 'Biscoe', 38.2, 20.0, 190.0, 3900.0, 'MALE'),\n",
       " (108, 'Adelie', 'Biscoe', 38.1, 17.0, 181.0, 3175.0, 'FEMALE'),\n",
       " (109, 'Adelie', 'Biscoe', 43.2, 19.0, 197.0, 4775.0, 'MALE'),\n",
       " (110, 'Adelie', 'Biscoe', 38.1, 16.5, 198.0, 3825.0, 'FEMALE'),\n",
       " (111, 'Adelie', 'Biscoe', 45.6, 20.3, 191.0, 4600.0, 'MALE'),\n",
       " (112, 'Adelie', 'Biscoe', 39.7, 17.7, 193.0, 3200.0, 'FEMALE'),\n",
       " (113, 'Adelie', 'Biscoe', 42.2, 19.5, 197.0, 4275.0, 'MALE'),\n",
       " (114, 'Adelie', 'Biscoe', 39.6, 20.7, 191.0, 3900.0, 'FEMALE'),\n",
       " (115, 'Adelie', 'Biscoe', 42.7, 18.3, 196.0, 4075.0, 'MALE'),\n",
       " (116, 'Adelie', 'Torgersen', 38.6, 17.0, 188.0, 2900.0, 'FEMALE'),\n",
       " (117, 'Adelie', 'Torgersen', 37.3, 20.5, 199.0, 3775.0, 'MALE'),\n",
       " (118, 'Adelie', 'Torgersen', 35.7, 17.0, 189.0, 3350.0, 'FEMALE'),\n",
       " (119, 'Adelie', 'Torgersen', 41.1, 18.6, 189.0, 3325.0, 'MALE'),\n",
       " (120, 'Adelie', 'Torgersen', 36.2, 17.2, 187.0, 3150.0, 'FEMALE'),\n",
       " (121, 'Adelie', 'Torgersen', 37.7, 19.8, 198.0, 3500.0, 'MALE'),\n",
       " (122, 'Adelie', 'Torgersen', 40.2, 17.0, 176.0, 3450.0, 'FEMALE'),\n",
       " (123, 'Adelie', 'Torgersen', 41.4, 18.5, 202.0, 3875.0, 'MALE'),\n",
       " (124, 'Adelie', 'Torgersen', 35.2, 15.9, 186.0, 3050.0, 'FEMALE'),\n",
       " (125, 'Adelie', 'Torgersen', 40.6, 19.0, 199.0, 4000.0, 'MALE'),\n",
       " (126, 'Adelie', 'Torgersen', 38.8, 17.6, 191.0, 3275.0, 'FEMALE'),\n",
       " (127, 'Adelie', 'Torgersen', 41.5, 18.3, 195.0, 4300.0, 'MALE'),\n",
       " (128, 'Adelie', 'Torgersen', 39.0, 17.1, 191.0, 3050.0, 'FEMALE'),\n",
       " (129, 'Adelie', 'Torgersen', 44.1, 18.0, 210.0, 4000.0, 'MALE'),\n",
       " (130, 'Adelie', 'Torgersen', 38.5, 17.9, 190.0, 3325.0, 'FEMALE'),\n",
       " (131, 'Adelie', 'Torgersen', 43.1, 19.2, 197.0, 3500.0, 'MALE'),\n",
       " (132, 'Adelie', 'Dream', 36.8, 18.5, 193.0, 3500.0, 'FEMALE'),\n",
       " (133, 'Adelie', 'Dream', 37.5, 18.5, 199.0, 4475.0, 'MALE'),\n",
       " (134, 'Adelie', 'Dream', 38.1, 17.6, 187.0, 3425.0, 'FEMALE'),\n",
       " (135, 'Adelie', 'Dream', 41.1, 17.5, 190.0, 3900.0, 'MALE'),\n",
       " (136, 'Adelie', 'Dream', 35.6, 17.5, 191.0, 3175.0, 'FEMALE'),\n",
       " (137, 'Adelie', 'Dream', 40.2, 20.1, 200.0, 3975.0, 'MALE'),\n",
       " (138, 'Adelie', 'Dream', 37.0, 16.5, 185.0, 3400.0, 'FEMALE'),\n",
       " (139, 'Adelie', 'Dream', 39.7, 17.9, 193.0, 4250.0, 'MALE'),\n",
       " (140, 'Adelie', 'Dream', 40.2, 17.1, 193.0, 3400.0, 'FEMALE'),\n",
       " (141, 'Adelie', 'Dream', 40.6, 17.2, 187.0, 3475.0, 'MALE'),\n",
       " (142, 'Adelie', 'Dream', 32.1, 15.5, 188.0, 3050.0, 'FEMALE'),\n",
       " (143, 'Adelie', 'Dream', 40.7, 17.0, 190.0, 3725.0, 'MALE'),\n",
       " (144, 'Adelie', 'Dream', 37.3, 16.8, 192.0, 3000.0, 'FEMALE'),\n",
       " (145, 'Adelie', 'Dream', 39.0, 18.7, 185.0, 3650.0, 'MALE'),\n",
       " (146, 'Adelie', 'Dream', 39.2, 18.6, 190.0, 4250.0, 'MALE'),\n",
       " (147, 'Adelie', 'Dream', 36.6, 18.4, 184.0, 3475.0, 'FEMALE'),\n",
       " (148, 'Adelie', 'Dream', 36.0, 17.8, 195.0, 3450.0, 'FEMALE'),\n",
       " (149, 'Adelie', 'Dream', 37.8, 18.1, 193.0, 3750.0, 'MALE'),\n",
       " (150, 'Adelie', 'Dream', 36.0, 17.1, 187.0, 3700.0, 'FEMALE'),\n",
       " (151, 'Adelie', 'Dream', 41.5, 18.5, 201.0, 4000.0, 'MALE'),\n",
       " (152, 'Chinstrap', 'Dream', 46.5, 17.9, 192.0, 3500.0, 'FEMALE'),\n",
       " (153, 'Chinstrap', 'Dream', 50.0, 19.5, 196.0, 3900.0, 'MALE'),\n",
       " (154, 'Chinstrap', 'Dream', 51.3, 19.2, 193.0, 3650.0, 'MALE'),\n",
       " (155, 'Chinstrap', 'Dream', 45.4, 18.7, 188.0, 3525.0, 'FEMALE'),\n",
       " (156, 'Chinstrap', 'Dream', 52.7, 19.8, 197.0, 3725.0, 'MALE'),\n",
       " (157, 'Chinstrap', 'Dream', 45.2, 17.8, 198.0, 3950.0, 'FEMALE'),\n",
       " (158, 'Chinstrap', 'Dream', 46.1, 18.2, 178.0, 3250.0, 'FEMALE'),\n",
       " (159, 'Chinstrap', 'Dream', 51.3, 18.2, 197.0, 3750.0, 'MALE'),\n",
       " (160, 'Chinstrap', 'Dream', 46.0, 18.9, 195.0, 4150.0, 'FEMALE'),\n",
       " (161, 'Chinstrap', 'Dream', 51.3, 19.9, 198.0, 3700.0, 'MALE'),\n",
       " (162, 'Chinstrap', 'Dream', 46.6, 17.8, 193.0, 3800.0, 'FEMALE'),\n",
       " (163, 'Chinstrap', 'Dream', 51.7, 20.3, 194.0, 3775.0, 'MALE'),\n",
       " (164, 'Chinstrap', 'Dream', 47.0, 17.3, 185.0, 3700.0, 'FEMALE'),\n",
       " (165, 'Chinstrap', 'Dream', 52.0, 18.1, 201.0, 4050.0, 'MALE'),\n",
       " (166, 'Chinstrap', 'Dream', 45.9, 17.1, 190.0, 3575.0, 'FEMALE'),\n",
       " (167, 'Chinstrap', 'Dream', 50.5, 19.6, 201.0, 4050.0, 'MALE'),\n",
       " (168, 'Chinstrap', 'Dream', 50.3, 20.0, 197.0, 3300.0, 'MALE'),\n",
       " (169, 'Chinstrap', 'Dream', 58.0, 17.8, 181.0, 3700.0, 'FEMALE'),\n",
       " (170, 'Chinstrap', 'Dream', 46.4, 18.6, 190.0, 3450.0, 'FEMALE'),\n",
       " (171, 'Chinstrap', 'Dream', 49.2, 18.2, 195.0, 4400.0, 'MALE'),\n",
       " (172, 'Chinstrap', 'Dream', 42.4, 17.3, 181.0, 3600.0, 'FEMALE'),\n",
       " (173, 'Chinstrap', 'Dream', 48.5, 17.5, 191.0, 3400.0, 'MALE'),\n",
       " (174, 'Chinstrap', 'Dream', 43.2, 16.6, 187.0, 2900.0, 'FEMALE'),\n",
       " (175, 'Chinstrap', 'Dream', 50.6, 19.4, 193.0, 3800.0, 'MALE'),\n",
       " (176, 'Chinstrap', 'Dream', 46.7, 17.9, 195.0, 3300.0, 'FEMALE'),\n",
       " (177, 'Chinstrap', 'Dream', 52.0, 19.0, 197.0, 4150.0, 'MALE'),\n",
       " (178, 'Chinstrap', 'Dream', 50.5, 18.4, 200.0, 3400.0, 'FEMALE'),\n",
       " (179, 'Chinstrap', 'Dream', 49.5, 19.0, 200.0, 3800.0, 'MALE'),\n",
       " (180, 'Chinstrap', 'Dream', 46.4, 17.8, 191.0, 3700.0, 'FEMALE'),\n",
       " (181, 'Chinstrap', 'Dream', 52.8, 20.0, 205.0, 4550.0, 'MALE'),\n",
       " (182, 'Chinstrap', 'Dream', 40.9, 16.6, 187.0, 3200.0, 'FEMALE'),\n",
       " (183, 'Chinstrap', 'Dream', 54.2, 20.8, 201.0, 4300.0, 'MALE'),\n",
       " (184, 'Chinstrap', 'Dream', 42.5, 16.7, 187.0, 3350.0, 'FEMALE'),\n",
       " (185, 'Chinstrap', 'Dream', 51.0, 18.8, 203.0, 4100.0, 'MALE'),\n",
       " (186, 'Chinstrap', 'Dream', 49.7, 18.6, 195.0, 3600.0, 'MALE'),\n",
       " (187, 'Chinstrap', 'Dream', 47.5, 16.8, 199.0, 3900.0, 'FEMALE'),\n",
       " (188, 'Chinstrap', 'Dream', 47.6, 18.3, 195.0, 3850.0, 'FEMALE'),\n",
       " (189, 'Chinstrap', 'Dream', 52.0, 20.7, 210.0, 4800.0, 'MALE'),\n",
       " (190, 'Chinstrap', 'Dream', 46.9, 16.6, 192.0, 2700.0, 'FEMALE'),\n",
       " (191, 'Chinstrap', 'Dream', 53.5, 19.9, 205.0, 4500.0, 'MALE'),\n",
       " (192, 'Chinstrap', 'Dream', 49.0, 19.5, 210.0, 3950.0, 'MALE'),\n",
       " (193, 'Chinstrap', 'Dream', 46.2, 17.5, 187.0, 3650.0, 'FEMALE'),\n",
       " (194, 'Chinstrap', 'Dream', 50.9, 19.1, 196.0, 3550.0, 'MALE'),\n",
       " (195, 'Chinstrap', 'Dream', 45.5, 17.0, 196.0, 3500.0, 'FEMALE'),\n",
       " (196, 'Chinstrap', 'Dream', 50.9, 17.9, 196.0, 3675.0, 'FEMALE'),\n",
       " (197, 'Chinstrap', 'Dream', 50.8, 18.5, 201.0, 4450.0, 'MALE'),\n",
       " (198, 'Chinstrap', 'Dream', 50.1, 17.9, 190.0, 3400.0, 'FEMALE'),\n",
       " (199, 'Chinstrap', 'Dream', 49.0, 19.6, 212.0, 4300.0, 'MALE'),\n",
       " (200, 'Chinstrap', 'Dream', 51.5, 18.7, 187.0, 3250.0, 'MALE'),\n",
       " (201, 'Chinstrap', 'Dream', 49.8, 17.3, 198.0, 3675.0, 'FEMALE'),\n",
       " (202, 'Chinstrap', 'Dream', 48.1, 16.4, 199.0, 3325.0, 'FEMALE'),\n",
       " (203, 'Chinstrap', 'Dream', 51.4, 19.0, 201.0, 3950.0, 'MALE'),\n",
       " (204, 'Chinstrap', 'Dream', 45.7, 17.3, 193.0, 3600.0, 'FEMALE'),\n",
       " (205, 'Chinstrap', 'Dream', 50.7, 19.7, 203.0, 4050.0, 'MALE'),\n",
       " (206, 'Chinstrap', 'Dream', 42.5, 17.3, 187.0, 3350.0, 'FEMALE'),\n",
       " (207, 'Chinstrap', 'Dream', 52.2, 18.8, 197.0, 3450.0, 'MALE'),\n",
       " (208, 'Chinstrap', 'Dream', 45.2, 16.6, 191.0, 3250.0, 'FEMALE'),\n",
       " (209, 'Chinstrap', 'Dream', 49.3, 19.9, 203.0, 4050.0, 'MALE'),\n",
       " (210, 'Chinstrap', 'Dream', 50.2, 18.8, 202.0, 3800.0, 'MALE'),\n",
       " (211, 'Chinstrap', 'Dream', 45.6, 19.4, 194.0, 3525.0, 'FEMALE'),\n",
       " (212, 'Chinstrap', 'Dream', 51.9, 19.5, 206.0, 3950.0, 'MALE'),\n",
       " (213, 'Chinstrap', 'Dream', 46.8, 16.5, 189.0, 3650.0, 'FEMALE'),\n",
       " (214, 'Chinstrap', 'Dream', 45.7, 17.0, 195.0, 3650.0, 'FEMALE'),\n",
       " (215, 'Chinstrap', 'Dream', 55.8, 19.8, 207.0, 4000.0, 'MALE'),\n",
       " (216, 'Chinstrap', 'Dream', 43.5, 18.1, 202.0, 3400.0, 'FEMALE'),\n",
       " (217, 'Chinstrap', 'Dream', 49.6, 18.2, 193.0, 3775.0, 'MALE'),\n",
       " (218, 'Chinstrap', 'Dream', 50.8, 19.0, 210.0, 4100.0, 'MALE'),\n",
       " (219, 'Chinstrap', 'Dream', 50.2, 18.7, 198.0, 3775.0, 'FEMALE'),\n",
       " (220, 'Gentoo', 'Biscoe', 46.1, 13.2, 211.0, 4500.0, 'FEMALE'),\n",
       " (221, 'Gentoo', 'Biscoe', 50.0, 16.3, 230.0, 5700.0, 'MALE'),\n",
       " (222, 'Gentoo', 'Biscoe', 48.7, 14.1, 210.0, 4450.0, 'FEMALE'),\n",
       " (223, 'Gentoo', 'Biscoe', 50.0, 15.2, 218.0, 5700.0, 'MALE'),\n",
       " (224, 'Gentoo', 'Biscoe', 47.6, 14.5, 215.0, 5400.0, 'MALE'),\n",
       " (225, 'Gentoo', 'Biscoe', 46.5, 13.5, 210.0, 4550.0, 'FEMALE'),\n",
       " (226, 'Gentoo', 'Biscoe', 45.4, 14.6, 211.0, 4800.0, 'FEMALE'),\n",
       " (227, 'Gentoo', 'Biscoe', 46.7, 15.3, 219.0, 5200.0, 'MALE'),\n",
       " (228, 'Gentoo', 'Biscoe', 43.3, 13.4, 209.0, 4400.0, 'FEMALE'),\n",
       " (229, 'Gentoo', 'Biscoe', 46.8, 15.4, 215.0, 5150.0, 'MALE'),\n",
       " (230, 'Gentoo', 'Biscoe', 40.9, 13.7, 214.0, 4650.0, 'FEMALE'),\n",
       " (231, 'Gentoo', 'Biscoe', 49.0, 16.1, 216.0, 5550.0, 'MALE'),\n",
       " (232, 'Gentoo', 'Biscoe', 45.5, 13.7, 214.0, 4650.0, 'FEMALE'),\n",
       " (233, 'Gentoo', 'Biscoe', 48.4, 14.6, 213.0, 5850.0, 'MALE'),\n",
       " (234, 'Gentoo', 'Biscoe', 45.8, 14.6, 210.0, 4200.0, 'FEMALE'),\n",
       " (235, 'Gentoo', 'Biscoe', 49.3, 15.7, 217.0, 5850.0, 'MALE'),\n",
       " (236, 'Gentoo', 'Biscoe', 42.0, 13.5, 210.0, 4150.0, 'FEMALE'),\n",
       " (237, 'Gentoo', 'Biscoe', 49.2, 15.2, 221.0, 6300.0, 'MALE'),\n",
       " (238, 'Gentoo', 'Biscoe', 46.2, 14.5, 209.0, 4800.0, 'FEMALE'),\n",
       " (239, 'Gentoo', 'Biscoe', 48.7, 15.1, 222.0, 5350.0, 'MALE'),\n",
       " (240, 'Gentoo', 'Biscoe', 50.2, 14.3, 218.0, 5700.0, 'MALE'),\n",
       " (241, 'Gentoo', 'Biscoe', 45.1, 14.5, 215.0, 5000.0, 'FEMALE'),\n",
       " (242, 'Gentoo', 'Biscoe', 46.5, 14.5, 213.0, 4400.0, 'FEMALE'),\n",
       " (243, 'Gentoo', 'Biscoe', 46.3, 15.8, 215.0, 5050.0, 'MALE'),\n",
       " (244, 'Gentoo', 'Biscoe', 42.9, 13.1, 215.0, 5000.0, 'FEMALE'),\n",
       " (245, 'Gentoo', 'Biscoe', 46.1, 15.1, 215.0, 5100.0, 'MALE'),\n",
       " (246, 'Gentoo', 'Biscoe', 44.5, 14.3, 216.0, 4100.0, None),\n",
       " (247, 'Gentoo', 'Biscoe', 47.8, 15.0, 215.0, 5650.0, 'MALE'),\n",
       " (248, 'Gentoo', 'Biscoe', 48.2, 14.3, 210.0, 4600.0, 'FEMALE'),\n",
       " (249, 'Gentoo', 'Biscoe', 50.0, 15.3, 220.0, 5550.0, 'MALE'),\n",
       " (250, 'Gentoo', 'Biscoe', 47.3, 15.3, 222.0, 5250.0, 'MALE'),\n",
       " (251, 'Gentoo', 'Biscoe', 42.8, 14.2, 209.0, 4700.0, 'FEMALE'),\n",
       " (252, 'Gentoo', 'Biscoe', 45.1, 14.5, 207.0, 5050.0, 'FEMALE'),\n",
       " (253, 'Gentoo', 'Biscoe', 59.6, 17.0, 230.0, 6050.0, 'MALE'),\n",
       " (254, 'Gentoo', 'Biscoe', 49.1, 14.8, 220.0, 5150.0, 'FEMALE'),\n",
       " (255, 'Gentoo', 'Biscoe', 48.4, 16.3, 220.0, 5400.0, 'MALE'),\n",
       " (256, 'Gentoo', 'Biscoe', 42.6, 13.7, 213.0, 4950.0, 'FEMALE'),\n",
       " (257, 'Gentoo', 'Biscoe', 44.4, 17.3, 219.0, 5250.0, 'MALE'),\n",
       " (258, 'Gentoo', 'Biscoe', 44.0, 13.6, 208.0, 4350.0, 'FEMALE'),\n",
       " (259, 'Gentoo', 'Biscoe', 48.7, 15.7, 208.0, 5350.0, 'MALE'),\n",
       " (260, 'Gentoo', 'Biscoe', 42.7, 13.7, 208.0, 3950.0, 'FEMALE'),\n",
       " (261, 'Gentoo', 'Biscoe', 49.6, 16.0, 225.0, 5700.0, 'MALE'),\n",
       " (262, 'Gentoo', 'Biscoe', 45.3, 13.7, 210.0, 4300.0, 'FEMALE'),\n",
       " (263, 'Gentoo', 'Biscoe', 49.6, 15.0, 216.0, 4750.0, 'MALE'),\n",
       " (264, 'Gentoo', 'Biscoe', 50.5, 15.9, 222.0, 5550.0, 'MALE'),\n",
       " (265, 'Gentoo', 'Biscoe', 43.6, 13.9, 217.0, 4900.0, 'FEMALE'),\n",
       " (266, 'Gentoo', 'Biscoe', 45.5, 13.9, 210.0, 4200.0, 'FEMALE'),\n",
       " (267, 'Gentoo', 'Biscoe', 50.5, 15.9, 225.0, 5400.0, 'MALE'),\n",
       " (268, 'Gentoo', 'Biscoe', 44.9, 13.3, 213.0, 5100.0, 'FEMALE'),\n",
       " (269, 'Gentoo', 'Biscoe', 45.2, 15.8, 215.0, 5300.0, 'MALE'),\n",
       " (270, 'Gentoo', 'Biscoe', 46.6, 14.2, 210.0, 4850.0, 'FEMALE'),\n",
       " (271, 'Gentoo', 'Biscoe', 48.5, 14.1, 220.0, 5300.0, 'MALE'),\n",
       " (272, 'Gentoo', 'Biscoe', 45.1, 14.4, 210.0, 4400.0, 'FEMALE'),\n",
       " (273, 'Gentoo', 'Biscoe', 50.1, 15.0, 225.0, 5000.0, 'MALE'),\n",
       " (274, 'Gentoo', 'Biscoe', 46.5, 14.4, 217.0, 4900.0, 'FEMALE'),\n",
       " (275, 'Gentoo', 'Biscoe', 45.0, 15.4, 220.0, 5050.0, 'MALE'),\n",
       " (276, 'Gentoo', 'Biscoe', 43.8, 13.9, 208.0, 4300.0, 'FEMALE'),\n",
       " (277, 'Gentoo', 'Biscoe', 45.5, 15.0, 220.0, 5000.0, 'MALE'),\n",
       " (278, 'Gentoo', 'Biscoe', 43.2, 14.5, 208.0, 4450.0, 'FEMALE'),\n",
       " (279, 'Gentoo', 'Biscoe', 50.4, 15.3, 224.0, 5550.0, 'MALE'),\n",
       " (280, 'Gentoo', 'Biscoe', 45.3, 13.8, 208.0, 4200.0, 'FEMALE'),\n",
       " (281, 'Gentoo', 'Biscoe', 46.2, 14.9, 221.0, 5300.0, 'MALE'),\n",
       " (282, 'Gentoo', 'Biscoe', 45.7, 13.9, 214.0, 4400.0, 'FEMALE'),\n",
       " (283, 'Gentoo', 'Biscoe', 54.3, 15.7, 231.0, 5650.0, 'MALE'),\n",
       " (284, 'Gentoo', 'Biscoe', 45.8, 14.2, 219.0, 4700.0, 'FEMALE'),\n",
       " (285, 'Gentoo', 'Biscoe', 49.8, 16.8, 230.0, 5700.0, 'MALE'),\n",
       " (286, 'Gentoo', 'Biscoe', 46.2, 14.4, 214.0, 4650.0, None),\n",
       " (287, 'Gentoo', 'Biscoe', 49.5, 16.2, 229.0, 5800.0, 'MALE'),\n",
       " (288, 'Gentoo', 'Biscoe', 43.5, 14.2, 220.0, 4700.0, 'FEMALE'),\n",
       " (289, 'Gentoo', 'Biscoe', 50.7, 15.0, 223.0, 5550.0, 'MALE'),\n",
       " (290, 'Gentoo', 'Biscoe', 47.7, 15.0, 216.0, 4750.0, 'FEMALE'),\n",
       " (291, 'Gentoo', 'Biscoe', 46.4, 15.6, 221.0, 5000.0, 'MALE'),\n",
       " (292, 'Gentoo', 'Biscoe', 48.2, 15.6, 221.0, 5100.0, 'MALE'),\n",
       " (293, 'Gentoo', 'Biscoe', 46.5, 14.8, 217.0, 5200.0, 'FEMALE'),\n",
       " (294, 'Gentoo', 'Biscoe', 46.4, 15.0, 216.0, 4700.0, 'FEMALE'),\n",
       " (295, 'Gentoo', 'Biscoe', 48.6, 16.0, 230.0, 5800.0, 'MALE'),\n",
       " (296, 'Gentoo', 'Biscoe', 47.5, 14.2, 209.0, 4600.0, 'FEMALE'),\n",
       " (297, 'Gentoo', 'Biscoe', 51.1, 16.3, 220.0, 6000.0, 'MALE'),\n",
       " (298, 'Gentoo', 'Biscoe', 45.2, 13.8, 215.0, 4750.0, 'FEMALE'),\n",
       " (299, 'Gentoo', 'Biscoe', 45.2, 16.4, 223.0, 5950.0, 'MALE'),\n",
       " (300, 'Gentoo', 'Biscoe', 49.1, 14.5, 212.0, 4625.0, 'FEMALE'),\n",
       " (301, 'Gentoo', 'Biscoe', 52.5, 15.6, 221.0, 5450.0, 'MALE'),\n",
       " (302, 'Gentoo', 'Biscoe', 47.4, 14.6, 212.0, 4725.0, 'FEMALE'),\n",
       " (303, 'Gentoo', 'Biscoe', 50.0, 15.9, 224.0, 5350.0, 'MALE'),\n",
       " (304, 'Gentoo', 'Biscoe', 44.9, 13.8, 212.0, 4750.0, 'FEMALE'),\n",
       " (305, 'Gentoo', 'Biscoe', 50.8, 17.3, 228.0, 5600.0, 'MALE'),\n",
       " (306, 'Gentoo', 'Biscoe', 43.4, 14.4, 218.0, 4600.0, 'FEMALE'),\n",
       " (307, 'Gentoo', 'Biscoe', 51.3, 14.2, 218.0, 5300.0, 'MALE'),\n",
       " (308, 'Gentoo', 'Biscoe', 47.5, 14.0, 212.0, 4875.0, 'FEMALE'),\n",
       " (309, 'Gentoo', 'Biscoe', 52.1, 17.0, 230.0, 5550.0, 'MALE'),\n",
       " (310, 'Gentoo', 'Biscoe', 47.5, 15.0, 218.0, 4950.0, 'FEMALE'),\n",
       " (311, 'Gentoo', 'Biscoe', 52.2, 17.1, 228.0, 5400.0, 'MALE'),\n",
       " (312, 'Gentoo', 'Biscoe', 45.5, 14.5, 212.0, 4750.0, 'FEMALE'),\n",
       " (313, 'Gentoo', 'Biscoe', 49.5, 16.1, 224.0, 5650.0, 'MALE'),\n",
       " (314, 'Gentoo', 'Biscoe', 44.5, 14.7, 214.0, 4850.0, 'FEMALE'),\n",
       " (315, 'Gentoo', 'Biscoe', 50.8, 15.7, 226.0, 5200.0, 'MALE'),\n",
       " (316, 'Gentoo', 'Biscoe', 49.4, 15.8, 216.0, 4925.0, 'MALE'),\n",
       " (317, 'Gentoo', 'Biscoe', 46.9, 14.6, 222.0, 4875.0, 'FEMALE'),\n",
       " (318, 'Gentoo', 'Biscoe', 48.4, 14.4, 203.0, 4625.0, 'FEMALE'),\n",
       " (319, 'Gentoo', 'Biscoe', 51.1, 16.5, 225.0, 5250.0, 'MALE'),\n",
       " (320, 'Gentoo', 'Biscoe', 48.5, 15.0, 219.0, 4850.0, 'FEMALE'),\n",
       " (321, 'Gentoo', 'Biscoe', 55.9, 17.0, 228.0, 5600.0, 'MALE'),\n",
       " (322, 'Gentoo', 'Biscoe', 47.2, 15.5, 215.0, 4975.0, 'FEMALE'),\n",
       " (323, 'Gentoo', 'Biscoe', 49.1, 15.0, 228.0, 5500.0, 'MALE'),\n",
       " (324, 'Gentoo', 'Biscoe', 47.3, 13.8, 216.0, 4725.0, None),\n",
       " (325, 'Gentoo', 'Biscoe', 46.8, 16.1, 215.0, 5500.0, 'MALE'),\n",
       " (326, 'Gentoo', 'Biscoe', 41.7, 14.7, 210.0, 4700.0, 'FEMALE'),\n",
       " (327, 'Gentoo', 'Biscoe', 53.4, 15.8, 219.0, 5500.0, 'MALE'),\n",
       " (328, 'Gentoo', 'Biscoe', 43.3, 14.0, 208.0, 4575.0, 'FEMALE'),\n",
       " (329, 'Gentoo', 'Biscoe', 48.1, 15.1, 209.0, 5500.0, 'MALE'),\n",
       " (330, 'Gentoo', 'Biscoe', 50.5, 15.2, 216.0, 5000.0, 'FEMALE'),\n",
       " (331, 'Gentoo', 'Biscoe', 49.8, 15.9, 229.0, 5950.0, 'MALE'),\n",
       " (332, 'Gentoo', 'Biscoe', 43.5, 15.2, 213.0, 4650.0, 'FEMALE'),\n",
       " (333, 'Gentoo', 'Biscoe', 51.5, 16.3, 230.0, 5500.0, 'MALE'),\n",
       " (334, 'Gentoo', 'Biscoe', 46.2, 14.1, 217.0, 4375.0, 'FEMALE'),\n",
       " (335, 'Gentoo', 'Biscoe', 55.1, 16.0, 230.0, 5850.0, 'MALE'),\n",
       " (336, 'Gentoo', 'Biscoe', 44.5, 15.7, 217.0, 4875.0, None),\n",
       " (337, 'Gentoo', 'Biscoe', 48.8, 16.2, 222.0, 6000.0, 'MALE'),\n",
       " (338, 'Gentoo', 'Biscoe', 47.2, 13.7, 214.0, 4925.0, 'FEMALE'),\n",
       " (339, 'Gentoo', 'Biscoe', None, None, None, None, None),\n",
       " (340, 'Gentoo', 'Biscoe', 46.8, 14.3, 215.0, 4850.0, 'FEMALE'),\n",
       " (341, 'Gentoo', 'Biscoe', 50.4, 15.7, 222.0, 5750.0, 'MALE'),\n",
       " (342, 'Gentoo', 'Biscoe', 45.2, 14.8, 212.0, 5200.0, 'FEMALE'),\n",
       " (343, 'Gentoo', 'Biscoe', 49.9, 16.1, 213.0, 5400.0, 'MALE')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "494ec6ed-de74-4072-b7ba-9042cc68b01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 344 entries, 0 to 343\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   species            344 non-null    object \n",
      " 1   island             344 non-null    object \n",
      " 2   bill_length_mm     342 non-null    float64\n",
      " 3   bill_depth_mm      342 non-null    float64\n",
      " 4   flipper_length_mm  342 non-null    float64\n",
      " 5   body_mass_g        342 non-null    float64\n",
      " 6   sex                333 non-null    object \n",
      "dtypes: float64(4), object(3)\n",
      "memory usage: 18.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b7eeaa6-1458-481f-a243-7c097cd6c613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prefix(query):\n",
    "    prefix = f\"\"\" Return a sql statement that answers the following query:\n",
    "    {query}\n",
    "    For a table called 'Penguins' with the following property\n",
    "          #   Column             Non-Null Count  Dtype  \n",
    "         ---  ------             --------------  -----  \n",
    "          0   species            344 non-null    object \n",
    "          1   island             344 non-null    object \n",
    "          2   bill_length_mm     342 non-null    float64\n",
    "          3   bill_depth_mm      342 non-null    float64\n",
    "          4   flipper_length_mm  342 non-null    float64\n",
    "          5   body_mass_g        342 non-null    float64\n",
    "          6   sex                333 non-null    object \n",
    " \n",
    "    Example Rows:\n",
    "    (0, 'Adelie', 'Torgersen', 39.1, 18.7, 181.0, 3750.0, 'MALE'),\n",
    "    (1, 'Adelie', 'Torgersen', 39.5, 17.4, 186.0, 3800.0, 'FEMALE')\n",
    " \n",
    "     Only return the Sql statement for the query.\n",
    "    \"\"\"\n",
    "    return prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6eca31be-1c2f-46d3-be3f-e3ca594ce7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_input():\n",
    "    query = input(\"Ask a question about the Penguins table\")\n",
    "    return create_prefix(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90ba0516-f55b-4c58-bcbe-c8d000a4d030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ask a question about the Penguins table How many penguins are there in the table?\n"
     ]
    }
   ],
   "source": [
    "prefix = user_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8b0b012-70af-4af7-baae-e8393941c33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Return a sql statement that answers the following query:\n",
      "    How many penguins are there in the table?\n",
      "    For a table called 'Penguins' with the following property\n",
      "          #   Column             Non-Null Count  Dtype  \n",
      "         ---  ------             --------------  -----  \n",
      "          0   species            344 non-null    object \n",
      "          1   island             344 non-null    object \n",
      "          2   bill_length_mm     342 non-null    float64\n",
      "          3   bill_depth_mm      342 non-null    float64\n",
      "          4   flipper_length_mm  342 non-null    float64\n",
      "          5   body_mass_g        342 non-null    float64\n",
      "          6   sex                333 non-null    object \n",
      " \n",
      "    Example Rows:\n",
      "    (0, 'Adelie', 'Torgersen', 39.1, 18.7, 181.0, 3750.0, 'MALE'),\n",
      "    (1, 'Adelie', 'Torgersen', 39.5, 17.4, 186.0, 3800.0, 'FEMALE')\n",
      " \n",
      "     Only return the Sql statement for the query.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32903b66-8ed6-4238-8b28-32fff931fc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\varun\\anaconda3\\lib\\site-packages (0.28.1)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from openai) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\varun\\anaconda3\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\varun\\anaconda3\\lib\\site-packages (from openai) (3.10.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (2024.8.30)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from aiohttp->openai) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from aiohttp->openai) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from aiohttp->openai) (1.11.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from aiohttp->openai) (4.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\varun\\anaconda3\\lib\\site-packages (from tqdm->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9a6968b-4961-4a20-96f4-2588cf812030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9713fb43-991c-41e9-b4e9-0c8020d311d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c33afe34-77d1-438d-9ed8-c930af90f096",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f4a844e1-2c9e-4b60-95b9-13030537fc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenAICodeGenModel:\n",
    "    def __init__(self, model=\"gpt-4\", api_key=None):\n",
    "        self.model = model\n",
    "        if api_key:\n",
    "            openai.api_key = api_key\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, model_name, api_key=None):\n",
    "        return cls(model=model_name, api_key=api_key)\n",
    "\n",
    "    def predict(self, prompt, temperature=0.3, max_tokens=256):\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that writes SQL queries.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens\n",
    "        )\n",
    "        raw_text = response.choices[0].message.content.strip()\n",
    "\n",
    "        # Extract only the SQL statement from the response (remove extra text)\n",
    "        sql_query = re.sub(r'^(Here is the SQL statement that would answer your query:|Only return the SQL statement for the query.)', '', raw_text).strip()\n",
    "\n",
    "        return sql_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "75d3154c-61ac-499c-8b21-e9c45195fa57",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (4025275321.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Varun\\AppData\\Local\\Temp\\ipykernel_18212\\4025275321.py\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    {query}\u001b[0m\n\u001b[1;37m           \n^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d28dec46-ca38-4660-bc6f-f9cd82136d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prefix(query, conversation_history):\n",
    "    # Add the query to the conversation history\n",
    "    conversation_history.append({\"role\": \"user\", \"content\": query})\n",
    "    \n",
    "    # Construct the prompt with the conversation history\n",
    "    prompt = f\"\"\"Return a SQL statement that answers the following query:\n",
    "{query}\n",
    "\n",
    "For a table called 'Penguins' with the following properties:\n",
    "  #   Column             Non-Null Count  Dtype  \n",
    " ---  ------             --------------  -----  \n",
    "  0   species            344 non-null    object \n",
    "  1   island             344 non-null    object \n",
    "  2   bill_length_mm     342 non-null    float64\n",
    "  3   bill_depth_mm      342 non-null    float64\n",
    "  4   flipper_length_mm  342 non-null    float64\n",
    "  5   body_mass_g        342 non-null    float64\n",
    "  6   sex                333 non-null    object \n",
    "\n",
    "Example Rows:\n",
    "(0, 'Adelie', 'Torgersen', 39.1, 18.7, 181.0, 3750.0, 'MALE'),\n",
    "(1, 'Adelie', 'Torgersen', 39.5, 17.4, 186.0, 3800.0, 'FEMALE')\n",
    "\n",
    "Only return the SQL statement for the query.\n",
    "\"\"\" \n",
    "    conversation_history.append({\"role\": \"assistant\", \"content\": prompt})\n",
    "    return conversation_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "562e7891-0a30-4abe-860c-4ab75ca0a9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OpenAICodeGenModel.from_pretrained(\"gpt-4\", api_key=api_key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "31946f79-4ff9-4a19-8dd4-1cfcb5aebfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"sqlite:///penguins.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "25f97a8f-5821-4715-85e8-8d5519b728a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am your AI Database Assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello, I am your AI Database Assistant\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "31d3f41a-de6a-4955-b913-abac0157c241",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "26ac5556-4660-494c-b620-117e57e01a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "I am your AI Database Assiatnt, please enter your queries:  What is the bill depth of aledie on torgersen island\n"
     ]
    },
    {
     "ename": "InvalidRequestError",
     "evalue": "Missing required parameter: 'messages[1].content[0].type'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18212\\3496820614.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# Generate SQL query from the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0msql_query\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconversation_history\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"\\n🔎 Generated SQL:\\n{sql_query}\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18212\\617439360.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, prompt, temperature, max_tokens)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         response = openai.ChatCompletion.create(\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             messages=[\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\api_resources\\chat_completion.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    153\u001b[0m         )\n\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[0;32m    156\u001b[0m             \u001b[1;34m\"post\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m         )\n\u001b[1;32m--> 299\u001b[1;33m         \u001b[0mresp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    708\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m             return (\n\u001b[1;32m--> 710\u001b[1;33m                 self._interpret_response_line(\n\u001b[0m\u001b[0;32m    711\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\openai\\api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    773\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"error\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    774\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;36m200\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 775\u001b[1;33m             raise self.handle_error_response(\n\u001b[0m\u001b[0;32m    776\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m             )\n",
      "\u001b[1;31mInvalidRequestError\u001b[0m: Missing required parameter: 'messages[1].content[0].type'."
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_query = input(\"I am your AI Database Assiatnt, please enter your queries: \")\n",
    "    if user_query.lower() == \"exit\":\n",
    "        break\n",
    "\n",
    "     # Update conversation history and generate the prompt\n",
    "    conversation_history = create_prefix(user_query, conversation_history)\n",
    "\n",
    "    # Generate SQL query from the model\n",
    "    sql_query = model.predict(conversation_history)\n",
    "\n",
    "    print(f\"\\n🔎 Generated SQL:\\n{sql_query}\\n\")\n",
    "\n",
    "    # Execute the query safely\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            result = conn.execute(text(sql_query))\n",
    "            rows = result.fetchall()\n",
    "\n",
    "            if rows:\n",
    "                print(\"📊 Results:\")\n",
    "                for row in rows:\n",
    "                    print(dict(row))\n",
    "            else:\n",
    "                print(\"✅ Query ran successfully but returned no rows.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error executing SQL: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "748027c6-7f55-47d2-8904-264ffa987cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am your AI Database Assistant\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your natural language question (or type 'exit' to quit):  exit\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from sqlalchemy import create_engine, text\n",
    "import re\n",
    "\n",
    "# Set your OpenAI API Key\n",
    "openai.api_key = api_key  # Replace with your actual key\n",
    "\n",
    "# --- CodeGen model wrapper ---\n",
    "class OpenAICodeGenModel:\n",
    "    def __init__(self, model=\"gpt-4\", api_key=None):\n",
    "        self.model = model\n",
    "        if api_key:\n",
    "            openai.api_key = api_key\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, model_name, api_key=None):\n",
    "        return cls(model=model_name, api_key=api_key)\n",
    "\n",
    "    def predict(self, messages, temperature=0.3, max_tokens=256):\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model,\n",
    "            messages=messages,  # Passing the entire conversation history\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens\n",
    "        )\n",
    "        raw_text = response.choices[0].message['content'].strip()\n",
    "\n",
    "        # Extract only the SQL statement from the response (remove extra text)\n",
    "        sql_query = re.sub(r'^(Here is the SQL statement that would answer your query:|Only return the SQL statement for the query.)', '', raw_text).strip()\n",
    "\n",
    "        return sql_query\n",
    "\n",
    "# --- Prefix generator for prompting ---\n",
    "def create_prefix(query, conversation_history):\n",
    "    # Add the query to the conversation history\n",
    "    conversation_history.append({\"role\": \"user\", \"content\": query})\n",
    "    \n",
    "    # Construct the prompt with the conversation history\n",
    "    prompt = f\"\"\"Return a SQL statement that answers the following query:\n",
    "{query}\n",
    "\n",
    "For a table called 'Penguins' with the following properties:\n",
    "  #   Column             Non-Null Count  Dtype  \n",
    " ---  ------             --------------  -----  \n",
    "  0   species            344 non-null    object \n",
    "  1   island             344 non-null    object \n",
    "  2   bill_length_mm     342 non-null    float64\n",
    "  3   bill_depth_mm      342 non-null    float64\n",
    "  4   flipper_length_mm  342 non-null    float64\n",
    "  5   body_mass_g        342 non-null    float64\n",
    "  6   sex                333 non-null    object \n",
    "\n",
    "Example Rows:\n",
    "(0, 'Adelie', 'Torgersen', 39.1, 18.7, 181.0, 3750.0, 'MALE'),\n",
    "(1, 'Adelie', 'Torgersen', 39.5, 17.4, 186.0, 3800.0, 'FEMALE')\n",
    "\n",
    "Only return the SQL statement for the query.\n",
    "\"\"\"\n",
    "    \n",
    "    # Add the assistant response placeholder (assistant’s role)\n",
    "    conversation_history.append({\"role\": \"assistant\", \"content\": prompt})\n",
    "\n",
    "    return conversation_history\n",
    "\n",
    "# --- Initialize model ---\n",
    "model = OpenAICodeGenModel.from_pretrained(\"gpt-4\")\n",
    "\n",
    "# --- Connect to DB (adjust URI as needed) ---\n",
    "engine = create_engine(\"sqlite:///penguins.db\")  # or your actual database URI\n",
    "\n",
    "# --- Main Loop ---\n",
    "print(\"Hello, I am your AI Database Assistant\\n\")\n",
    "\n",
    "# Initialize conversational buffer (history)\n",
    "conversation_history = []\n",
    "\n",
    "while True:\n",
    "    user_query = input(\"Enter your natural language question (or type 'exit' to quit): \")\n",
    "    if user_query.lower() == \"exit\":\n",
    "        break\n",
    "\n",
    "    # Update conversation history and generate the prompt\n",
    "    conversation_history = create_prefix(user_query, conversation_history)\n",
    "\n",
    "    # Generate SQL query from the model\n",
    "    sql_query = model.predict(conversation_history)\n",
    "\n",
    "    print(f\"\\nGenerated SQL:\\n{sql_query}\\n\")\n",
    "\n",
    "    # Execute the query safely\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            result = conn.execute(text(sql_query))\n",
    "            rows = result.fetchall()\n",
    "\n",
    "            if rows:\n",
    "                print(\"📊 Results:\")\n",
    "                for row in rows:\n",
    "                    print(dict(row))\n",
    "            else:\n",
    "                print(\"Query ran successfully but returned no rows.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing SQL: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2ba37b21-0b27-4006-a105-ef06100fb307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am your AI Database Assistant\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your natural language question (or type 'exit' to quit):  What is the total number of aledie and other species on torgersen island?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔎 Generated SQL:\n",
      "SELECT species, COUNT(*) \n",
      "FROM Penguins \n",
      "WHERE island = 'Torgersen' \n",
      "GROUP BY species;\n",
      "\n",
      "❌ Error executing SQL: (sqlite3.OperationalError) no such table: Penguins\n",
      "[SQL: SELECT species, COUNT(*) \n",
      "FROM Penguins \n",
      "WHERE island = 'Torgersen' \n",
      "GROUP BY species;]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your natural language question (or type 'exit' to quit):  exit\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from sqlalchemy import create_engine, text\n",
    "import re\n",
    "\n",
    "# Set your OpenAI API Key\n",
    "openai.api_key = api_key # Replace with your actual key\n",
    "\n",
    "# --- CodeGen model wrapper ---\n",
    "class OpenAICodeGenModel:\n",
    "    def __init__(self, model=\"gpt-4\", api_key=None):\n",
    "        self.model = model\n",
    "        if api_key:\n",
    "            openai.api_key = api_key\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, model_name, api_key=None):\n",
    "        return cls(model=model_name, api_key=api_key)\n",
    "\n",
    "    def predict(self, messages, temperature=0.3, max_tokens=256):\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model,\n",
    "            messages=messages,  # Passing the entire conversation history\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens\n",
    "        )\n",
    "        raw_text = response.choices[0].message['content'].strip()\n",
    "\n",
    "        # Remove the code block markers (```sql``` and ```)\n",
    "        sql_query = re.sub(r'^(Here is the SQL statement that would answer your query:|Only return the SQL statement for the query.|```sql|\\n```)', '', raw_text).strip()\n",
    "\n",
    "        return sql_query\n",
    "\n",
    "# --- Prefix generator for prompting ---\n",
    "def create_prefix(query, conversation_history):\n",
    "    # Add the query to the conversation history\n",
    "    conversation_history.append({\"role\": \"user\", \"content\": query})\n",
    "    \n",
    "    # Construct the prompt with the conversation history\n",
    "    prompt = f\"\"\"Return a SQL statement that answers the following query:\n",
    "{query}\n",
    "\n",
    "For a table called 'Penguins' with the following properties:\n",
    "  #   Column             Non-Null Count  Dtype  \n",
    " ---  ------             --------------  -----  \n",
    "  0   species            344 non-null    object \n",
    "  1   island             344 non-null    object \n",
    "  2   bill_length_mm     342 non-null    float64\n",
    "  3   bill_depth_mm      342 non-null    float64\n",
    "  4   flipper_length_mm  342 non-null    float64\n",
    "  5   body_mass_g        342 non-null    float64\n",
    "  6   sex                333 non-null    object \n",
    "\n",
    "Example Rows:\n",
    "(0, 'Adelie', 'Torgersen', 39.1, 18.7, 181.0, 3750.0, 'MALE'),\n",
    "(1, 'Adelie', 'Torgersen', 39.5, 17.4, 186.0, 3800.0, 'FEMALE')\n",
    "\n",
    "Only return the SQL statement for the query.\n",
    "\"\"\"\n",
    "    \n",
    "    # Add the assistant response placeholder (assistant’s role)\n",
    "    conversation_history.append({\"role\": \"assistant\", \"content\": prompt})\n",
    "\n",
    "    return conversation_history\n",
    "\n",
    "# --- Initialize model ---\n",
    "model = OpenAICodeGenModel.from_pretrained(\"gpt-4\")\n",
    "\n",
    "# --- Connect to DB (adjust URI as needed) ---\n",
    "engine = create_engine(\"sqlite:///penguins.db\")  # or your actual database URI\n",
    "\n",
    "# --- Main Loop ---\n",
    "print(\"Hello, I am your AI Database Assistant\\n\")\n",
    "\n",
    "# Initialize conversational buffer (history)\n",
    "conversation_history = []\n",
    "\n",
    "while True:\n",
    "    user_query = input(\"Enter your natural language question (or type 'exit' to quit): \")\n",
    "    if user_query.lower() == \"exit\":\n",
    "        break\n",
    "\n",
    "    # Update conversation history and generate the prompt\n",
    "    conversation_history = create_prefix(user_query, conversation_history)\n",
    "\n",
    "    # Generate SQL query from the model\n",
    "    sql_query = model.predict(conversation_history)\n",
    "\n",
    "    print(f\"\\n🔎 Generated SQL:\\n{sql_query}\\n\")\n",
    "\n",
    "    # Execute the query safely\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            result = conn.execute(text(sql_query))\n",
    "            rows = result.fetchall()\n",
    "\n",
    "            if rows:\n",
    "                print(\"📊 Results:\")\n",
    "                for row in rows:\n",
    "                    print(dict(row))\n",
    "            else:\n",
    "                print(\"✅ Query ran successfully but returned no rows.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error executing SQL: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f210d3a1-2124-4345-a2d7-94f03294f052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am your AI Database Assistant\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your natural language question (or type 'exit' to quit):  Add new feature where if aledie on torgersen is greater than 30 than make it o or keep it as one \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Based on your description, it sounds like you want to create a new column (let's call it 'new_feature') in your table where if 'aledie' on 'torgersen' is greater than 30, then the value in the new column should be 0, otherwise it should be 1. However, your table structure doesn't seem to have 'aledie' column. \n",
      "\n",
      "Assuming 'aledie' is a typo and you meant 'Adelie' which is a species and 'Torgersen' is an island, and you want to apply the condition on 'bill_length_mm' which is a numeric column, here is how you can do it in SQL:\n",
      "\n",
      "```sql\n",
      "ALTER TABLE Penguins ADD new_feature int;\n",
      "\n",
      "UPDATE Penguins\n",
      "SET new_feature = CASE\n",
      "    WHEN species = 'Adelie' AND island = 'Torgersen' AND bill_length_mm > 30 THEN 0\n",
      "    ELSE 1\n",
      "END;\n",
      "```\n",
      "\n",
      "This will add a new column to your table and set its value based on the condition you specified. Please replace 'bill_length_mm' with the correct column if my assumption is incorrect.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your natural language question (or type 'exit' to quit):  is the above query correct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "I'm sorry for the confusion, but your initial request is a bit unclear. If you're asking to add a new column to a SQL table based on the condition of another column, you can't directly do that in SQL. However, you can create a query that will return a result set with the new column based on your condition. Here's an example:\n",
      "\n",
      "```sql\n",
      "SELECT *, \n",
      "CASE \n",
      "    WHEN aledie > 30 THEN 0 \n",
      "    ELSE 1 \n",
      "END as new_feature\n",
      "FROM Penguins\n",
      "WHERE island = 'Torgersen';\n",
      "```\n",
      "\n",
      "This query will return all columns from the 'Penguins' table and a new column called 'new_feature'. If the value of 'aledie' is greater than 30, 'new_feature' will be 0, otherwise it will be 1. This will only be for rows where 'island' is 'Torgersen'.\n",
      "\n",
      "Please replace 'aledie' with the correct column name as I made an assumption based on your initial request. If you need to update the actual table, you would need to create a new table or alter the existing table outside of the SQL query, which depends on your SQL database.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your natural language question (or type 'exit' to quit):  exit\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from sqlalchemy import create_engine, text\n",
    "import re\n",
    "\n",
    "# Set your OpenAI API Key\n",
    "openai.api_key = api_key  # Replace with your actual key\n",
    "\n",
    "# --- CodeGen model wrapper ---\n",
    "class OpenAICodeGenModel:\n",
    "    def __init__(self, model=\"gpt-4\", api_key=None):\n",
    "        self.model = model\n",
    "        if api_key:\n",
    "            openai.api_key = api_key\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, model_name, api_key=None):\n",
    "        return cls(model=model_name, api_key=api_key)\n",
    "\n",
    "    def predict(self, messages, temperature=0.3, max_tokens=256):\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=self.model,\n",
    "            messages=messages,  # Passing the entire conversation history\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens\n",
    "        )\n",
    "        raw_text = response.choices[0].message['content'].strip()\n",
    "\n",
    "        # Remove the code block markers (```sql``` and ```)\n",
    "        sql_query = re.sub(r'^(Here is the SQL statement that would answer your query:|Only return the SQL statement for the query.|```sql|\\n```)', '', raw_text).strip()\n",
    "\n",
    "        return sql_query\n",
    "\n",
    "# --- Prefix generator for prompting ---\n",
    "def create_prefix(query, conversation_history):\n",
    "    # Add the query to the conversation history\n",
    "    conversation_history.append({\"role\": \"user\", \"content\": query})\n",
    "    \n",
    "    # Construct the prompt with the conversation history\n",
    "    prompt = f\"\"\"Return a SQL statement that answers the following query:\n",
    "{query}\n",
    "\n",
    "For a table called 'Penguins' with the following properties:\n",
    "  #   Column             Non-Null Count  Dtype  \n",
    " ---  ------             --------------  -----  \n",
    "  0   species            344 non-null    object \n",
    "  1   island             344 non-null    object \n",
    "  2   bill_length_mm     342 non-null    float64\n",
    "  3   bill_depth_mm      342 non-null    float64\n",
    "  4   flipper_length_mm  342 non-null    float64\n",
    "  5   body_mass_g        342 non-null    float64\n",
    "  6   sex                333 non-null    object \n",
    "\n",
    "Example Rows:\n",
    "(0, 'Adelie', 'Torgersen', 39.1, 18.7, 181.0, 3750.0, 'MALE'),\n",
    "(1, 'Adelie', 'Torgersen', 39.5, 17.4, 186.0, 3800.0, 'FEMALE')\n",
    "\n",
    "Only return the SQL statement for the query.\n",
    "\"\"\"\n",
    "    \n",
    "    # Add the assistant response placeholder (assistant’s role)\n",
    "    conversation_history.append({\"role\": \"assistant\", \"content\": prompt})\n",
    "\n",
    "    return conversation_history\n",
    "\n",
    "# --- Initialize model ---\n",
    "model = OpenAICodeGenModel.from_pretrained(\"gpt-4\")\n",
    "\n",
    "# --- Connect to DB (adjust URI as needed) ---\n",
    "engine = create_engine(\"sqlite:///penguins.db\")  # or your actual database URI\n",
    "\n",
    "# --- Main Loop ---\n",
    "print(\"Hello, I am your AI Database Assistant\\n\")\n",
    "\n",
    "# Initialize conversational buffer (history)\n",
    "conversation_history = []\n",
    "\n",
    "while True:\n",
    "    user_query = input(\"Enter your natural language question (or type 'exit' to quit): \")\n",
    "    if user_query.lower() == \"exit\":\n",
    "        break\n",
    "\n",
    "    # Update conversation history and generate the prompt\n",
    "    conversation_history = create_prefix(user_query, conversation_history)\n",
    "\n",
    "    # Generate SQL query from the model\n",
    "    sql_query = model.predict(conversation_history)\n",
    "\n",
    "    print(f\"\\n{sql_query}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23eab09a-4eb5-4519-ae2b-08eab93c9da5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
